#MolecularOCRcrnn
Molecular OCR using convolutional recurrent neural networks

##Built on
This workflow is built on keras (using Theano). It also makes use of scikit-image (skimage) and the scientific python stack. Features are calculated based on SD files using RDkit.

##Acquiring data
As input data, place a dump of SD files (named "unique_id_XXXX.sdf") in data/SDF/

Compute features using `python fromSDFs.py`

Process features using `python ocrfeatures.py`

##Initialize a model
Based on what you want to learn (atom counts, bond counts, ring counts, etc) tweak a file in modelDefinitions/. By default the models are shallow and narrow to keep computational overhead relatively low. 

It might be useful to fiddle with:
	size (of images)
	batch_size (lower will help memory/batch)
	wSize (size of windows in the sequence)
	stride (number of pixels to move over/down before seeing new window)

For example from the scripts folder:
`python ../modelDefinitions/basicatoms.py`


##Generate Training/Test Data
Start 3 processes (for parallelism) - 2 will use the CPU purely and the other will train the model (possibly on the GPU). 

1) dataGenerator.py - creates images from the SD files in ../data/SDF using the renderer jar

	`python dataGenerator.py -s 300 -d ../basicatoms/300_1/ -t basicatoms`
	
	The above command creates images in ../basicatoms/300_1/ train/test folders of size 300x300 with otherwise default parameters
	For the full argument list see scripts/helperFuncs.py (dataGenArgs())

2) dataProcessorRNN.py - creates numpy arrays from the images in the train and test folders in the specified parent folder

	`python dataProcessorRNN.py -s 300 -d ../basicatoms/300_1/ -t basicatoms` 

	The above command will convert the clean images to numpy arrays of dimensions (number_of_examples, number_of_windows, 1_channel, window_size, window_size)

3) trainModel.py 
	
	`python trainModel.py ../basicatoms/300_1/`

	The above command will begin training your model on the numpy arrays above
